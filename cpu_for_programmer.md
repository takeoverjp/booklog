# プログラマーのためのCPU入門

## Links

- [プログラマーのためのCPU入門](https://www.lambdanote.com/products/cpu)

## 1. CPUは如何にしてソフトウェアを高速に実行するのか

- CPUは、「命令を順番に並べたものに基づいて、データの読み書きと加工を行う機械」
- 現代の汎用CPUは、広く使うことができるように、多様なアプリで共通して必要になる小さな操作が基本的な粒度となるように命令が設計されている
- 現代のCPUでは、特別な指示がない限り記述順序で後続の命令を次に実行すれば良い、という前提を置くことで高速化を実現するために、処理したい順番に命令を並べる方式が採用されている

## 2. 命令の密度を上げるさまざまな工夫

- CPUは、命令の処理を複数のステージに分割している。その分割の仕方はCPUによって異なるが、本書では便宜的に「命令フェッチ」「命令デコード」「命令実行」の３ステージとする。
- 逐次実行は安全で確実な処理方式だが、ステージごとにみるといつも２サイクルの待ちが発生する
- パイプライン処理では、選考命令の完了を待たずに次の命令を次々開始する方式をさし、逐次実行と比べて実行効率を飛躍的に控除することができるが、先行する命令の実行結果に応じたキャンセルが必要になりCPU設計はは複雑になる
- Meltdownはキャンセル処理の不適切さによって生じたセキュリティホール
- 「命令の実行サイクル数」は、主に命令実行ステージの先頭を起点として数える
- パイプライン化したCPUに対して、更に並列度を高め、処理帯域を向上するための方法として、スーパースカラ化とスーパーパイプライン化がある
- スーパースカラ化は、1クロックで処理可能な各ステージの命令数を増やす
- スーパーパイプライン化は、パイプラインステージを更に細分化することで、1クロックを短くする
- いずれのアプローチでも、１つの命令を処理しはじめて終わるまでのリードタイムは変わらず、CPU設計は複雑になり、限界がある

## 3. データ依存関係

### 3.1 データ依存関係とは

- ある２つの命令が、同一のレジスタやメモリ領域にアクセスする場合、その２つの命令間には「データ依存関係」があるという
- データ依存関係には、下記の４パターンがある
  - 真のデータ依存関係：ある命令の出力を後続の命令で入力として使う
  - 逆依存関係：ある命令の入力レジスタを、後続の命令の出力レジスタとして上書きする
  - 出力依存関係：ある命令と後続の命令の出力レジスタが重複している
  - 入力依存関係：ある命令と後続の命令の入力レジスタが重複している

### 3.2 真のデータ依存関係のスーパーパイプライン化への影響

- データの依存関係などにより、命令が実行できない無駄な空きサイクルのことを「ペナルティサイクル」と呼ぶ
- データの依存関係などにより、パイプラインの流れを妨げる要因や状況を「ハザード」と呼ぶ
- スーパーパイプラインでステージの分割段数を増やすほど、データ依存によるペナルティサイクルは増える

### 3.3 真のデータ依存関係のスーパースカラ化への影響

- スーパースカラで同時実行できるパイプライン数を増やせば増やすほど、データ依存による命令実行機会の影響は増える

### 3.4 アウト・オブ・オーダー実行による緩和

- アウト・オブ・オーダー実行（真のデータ依存関係がない別の命令開始を前倒しする）ことで、命令実行機会損失を緩和できる
- ただし、命令を前倒しするためには、その命令の内容がわかっていなければならないので、命令のフェッチとデコードが完了していなければならない
- 命令フェッチから命令でコードのステージを、まとめてフロントエンドと呼ぶ

### 3.5 最順序化（リオーダー）の必要性

- アウト・オブ・オーダー実行で、本来書き換えてはいけないレジスタやメモリの内容を書き換えることを避けるため、命令の実行後に最順序化（リオーダー）が必要
- リオーダーでは、アウト・オブ・オーダー実行した命令の実行結果を別の場所に保持しておいて、改めて命令実行完了後に本来の順番でレジスタやメモリに反映する。ここで、実際にレジスタやメモリに反映するステージを、「命令コミットステージ」あるいは「命令リタイヤステージ」と呼ぶ
- 本来の命令の実行順序を記憶しておくためのテーブルを「リオーダーバッファ」と呼び、そのサイズがアウト・オブ・オーダー実行により同時に処理できる命令の数を制限する要因の一つである

### 3.6 真ではないデータ依存関係への影響を解消する

- 逆依存関係と出力依存関係がある場合もそのままでは実行順序を入れ替えることができないが、出力レジスタを別の便宜上のレジスタに割り当てることで依存関係を解消し、実行順序を入れ替えることができる。この手法を「レジスタリネーム」と呼ぶ。便宜上のレジスタの個数も、アウト・オブ・オーダー実行により同時に処理できる命令の数を制限する要因の一つである

### 3.7 ソフトウェアによる緩和

#### 3.7.1 レイテンシ仕様を知る

- 真のデータ依存関係による影響は、先行命令の実行レイテンシが長いほど大きくなる
- `mov`, `add`, `shift`といった単純な命令はたいてい1サイクルで実行が完了するのに対し、`mul`, `div`のような回路規模が複雑な演算や、`load`のようなメモリアクセスは数サイクル〜数十サイクルかかる
- GCCでは、各CPUのおおまかなレイテンシ値を命令スケジューリングに使用している

#### 3.7.2 レイテンシが長い命令を避ける

- 定数による除算であり、かつ、精度が許す場合、逆数の乗算とすることで、10サイクル以上のレイテンシがかかりうる除算を、数サイクルの乗算に置き換える
- 2のべき乗の乗算を、レイテンシがより短いシフト命令に置き換える

#### 3.7.3 レイテンシが長い命令が先行されるように配置する

- ソフトウェアパイプライニング最適化
  - ループにおける次の周回の一部の命令を、現在のループ周回に前倒しする
  - https://ja.wikipedia.org/wiki/%E3%82%BD%E3%83%95%E3%83%88%E3%82%A6%E3%82%A7%E3%82%A2%E3%83%91%E3%82%A4%E3%83%97%E3%83%A9%E3%82%A4%E3%83%B3

#### 3.7.4 真のデータ依存関係のない命令で埋める

- ループアンローリング最適化
  - 次の周回にある真の依存関係のない処理を、現在のループ周回で一緒に実行することで、無駄な空きサイクルを埋める
  - ループアンローリングをすることで、使用するレジスタが増え、レジスタ不足による性能劣化につながる可能性もある

### 3.8 命令レイテンシの計測実験

- 命令のレイテンシをミクロなサイクル粒度で正確に計測することは困難なので、実行回数を多くして統計的に観測する
  - 本書では、10億回の平均を取っている
  - ループ自体の処理のノイズを減らすために、100回の命令をループ展開したプログラムにしている
  - すべての入出力レジスタを`rax`にすることで各命令間に真のデータ依存関係を発生させることで、スーパスカラによる同時実行を防ぎ、命令単位のレイテンシを計測可能にする

```
$ git clone https://github.com/takenobu-hs/cpu-assembly-examples.git
$ cd cpu-assembly-examples/x86/linux/E00.perf_expt
$ echo 1 | sudo tee /proc/sys/kernel/perf_event_paranoid setting
$ gcc -no-pie latency_add.S -o latency_add
$ perf stat -e "cycles,instructions" ./latency_add
loop-variable = 10000000

 Performance counter stats for './latency_add':

     1,002,841,414      cycles                                                      
     1,031,845,826      instructions              #    1.03  insn per cycle         

       0.230580767 seconds time elapsed

       0.230534000 seconds user
       0.000000000 seconds sys
$ gcc -no-pie latency_mul.S -o latency_mul
$ perf stat -e "cycles,instructions" ./latency_mul
loop-variable = 10000000

 Performance counter stats for './latency_mul':

     3,003,029,694      cycles                                                      
     1,032,332,191      instructions              #    0.34  insn per cycle         

       0.666553809 seconds time elapsed

       0.665895000 seconds user
       0.000000000 seconds sys


$ gcc -no-pie latency_load.S -o latency_load
$ perf stat -e "cycles,instructions" ./latency_load
loop-variable = 10000000

 Performance counter stats for './latency_load':

     5,007,364,513      cycles                                                      
     1,032,872,706      instructions              #    0.21  insn per cycle         

       1.096741547 seconds time elapsed

       1.096175000 seconds user
       0.000000000 seconds sys


```

- コンパイル時に`-no-pie`をつけているのは、PIEを考慮したアセンブリ実装になっていないから

#### 3.8.4 命令の同時実行を推定する

- 入出力レジスタを各命令ごとに変え、真のデータ依存を無くすことで、スーパスカラによる命令の同時実行数を推定することができる
- ただし、この手法で推定できるのは、このプログラムにおける並列実行数であり、最大の並列実行数でないことに注意が必要である。例えば、フロントエンドで並列度が律速している可能性がある。


#### 3.8.5 アウト・オブ・オーダー実行の特性を計測する

- レイテンシの長いload命令の後に、真のデータ依存関係があるadd命令を実行し、そのあと更に真のデータ依存関係がある処理だけを実行した場合と、そのあとは真のデータ依存関係がない処理を実行した場合とを比較することで、アウト・オブ・オーダー実行の効果を見ることができる
- ただし、一般的にCPUのミクロな挙動の正確な計測は難しい。特定の命令やレジスタの組み合わせにおいて実行が速くなったり遅くなったりするようにCPUが設計されている場合もある。あるいは、特定の条件下でCPUの特別な機能が作動し、通常と異なる挙動となる場合もある。

## 4. 分岐命令

### 4.1 分岐命令とその課題

- 「分岐」とは、本来の順序で次にくる命令と異なる命令を実行すること。（厳密には、「特権レベルの変更を伴わずに」）
- 「分岐」により、先行フェッチをキャンセルして、分岐先の命令のフェッチをやり直す必要がある（パイプラインがストールする）
  - 後続の命令が確定していないので、アウト・オブ・オーダー実行による緩和もできない
  - むしろアウト・オブ・オーダー実行により先行的に実行結果を生成してコミットを待っている命令群もキャンセル必要がある
  - 同じ時刻でパイプラインにある命令の中でも、分岐命令に先行する命令はコミットし、分岐命令以降はキャンセルする必要があり、このような場合分けによるキャンセル処理は、バグの温床となりがち
- CPUの不具合はErattaと呼ぶ。分岐命令やキャンセル系のミスが多い

### 4.2 分岐命令の種類

- 機能による分類
  - 無条件分岐命令
  - 条件分岐命令
  - コール命令・リターン命令：無条件分岐命令のように指定アドレスに処理を切り替えるが、その際に「プログラムの記述順で後続の命令のアドレス」を特別なレジスタ「復帰先アドレス」に保存しておく。リターン命令によって「復帰先アドレス」に復帰できる。

  - この区分や名前は、文献やCPUベンダによってもことなり、無条件分岐命令のことをジャンプ命令と呼ぶこともある

- 分岐先アドレス指定方法による分類
  - 直接分岐命令：オペランドに即値で指定する
  - 間接分岐命令：レジスタを介して指定する

### 4.3 分岐予測による緩和

- 「分岐予測」：実行ステージよりも早いステージで分岐先を予測し、分岐先の命令フェッチ開始を前倒しする。これにより、分岐命令の実行によって失われる命令実行機会の損失を緩和する

#### 4.3.1 分岐命令の存在の予測

- 過去に実行した分岐命令のアドレスを記録するためのテーブルを用意し、命令フェッチを行うたびにこのテーブルを確認することで予測する

#### 4.3.2 分岐先アドレスの予測

- 「BTB (Branch Target Buffer)」あるいは「BTAC (Branch Target Address Cache)」：4.3.1のテーブルに各エントリに分岐先のアドレスを１つ記録したテーブル。これを命令フェッチのタイミングで確認することで、分岐先アドレスを予測する
  - 記録する分岐先アドレスが１つなので、間接分岐命令やリターン命令では機能しない
  - 間接分岐命令の分岐先アドレスは、複数の分岐先アドレスを記録することで予測できる場合がある
  - リターン命令の分岐先アドレスは、コール時の次の命令アドレスをスタックで管理することで、高い精度で予測できる

#### 4.3.3 分岐条件の成立可否（分岐方向）の予測

- 「分岐履歴テーブル (branch history table, BHT)」あるいは「分岐履歴バッファ (branch history buffer, BHB)」：過去の分岐方向の履歴を格納するテーブル。このテーブルから分岐方向の組み合わせをキーに、分岐方向の予測値を取得する
- 該当の分岐命令における過去の分岐方向の履歴のみを用いる「ローカル予測方式」と、該当する分岐命令に至る他の分岐命令も含めた履歴を用いる「グローバル予測方式」がある

### 4.4 分岐予測ミスの影響と要因

- 分岐予測のヒット率は、およそ90%台の中盤程度。これはキャッシュのヒット率がおよそ90%台の後半であることと比べると低い傾向にある。

#### 4.4.1 過去の情報に基づくことに伴う要因

- 過去に実行されてない分岐命令は予測できない
- 過去の情報を記録するためのテーブルやスタックといった、ハードウェア面の制約にあたる

#### 4.4.2 予測対象が変化することに伴う要因

- 条件分岐命令では、予測対象自体が変化し続ける。この変化の仕方が不規則であったり、変化に偏りがない場合、予測は難しくなる
- 途中で分岐が起こらない命令列を「基本ブロック」と呼ぶ
- 基本ブロックを越えた命令実行の前倒しを（狭義の）「投機実行」と呼ぶ
- 投機実行の価値が特に大きいのは、「基本ブロックの先頭付近に配置されるレイテンシの長い命令」を基本ブロックを越えて前倒しできるところ。基本ブロックの先頭付近には、基本ブロック内を高速化できるように、一般にレイテンシの長い命令が配置されるため。
- 分岐予測が搭載されていても、インオーダー実行しかできない場合には投機実行ができないため、投機実行はアウトオブオーダー実行を導入する最大の動機である。

### 4.5 ソフトウェアによる緩和

#### 4.5.1 分岐命令をなくす

- 関数のインライン化。ただし、命令キャッシュを圧迫するデメリットがある
- 条件実行命令(`csel`, `cmov`など)を使って条件分岐命令を減らす

#### 4.5.2 分岐命令の実行回数を減らす

- ループ展開でループ回数(=分岐命令実行回数)を減らす。ただし、ループ回数が多いほうが分岐方向予測の成功率は高くなる可能性もある
- 複数の条件分岐命令が多重に実行される場合、実行頻度が高い経路を優先的に配置することで、全体の分岐命令の実行回数を減らせる可能性がある
  - →逆では？
    - 「条件が成立する(=実際に分岐する)可能性が高い条件分岐命令を先に配置する」ことで、「後続の条件分岐命令が実行されない可能性を高くする」ということか

#### 4.5.3 分岐予測の予測精度を高める

- 分岐方向や間接アドレスの値に偏りがあるほど、一般に予測が当たりやすい
  - 例えば、ループの回数を固定にする
  - 複数の条件分岐命令が多重に入れ子で実行される場合、実行される頻度が高く、かつ、分岐方向の偏りが大きい分岐命令を優先的に配置する
- `unlikely`の話はないのか

### 4.6 予測ミス率の計測実験

#### 4.6.1 分岐予測をほぼ完全に失敗させる例

- 「分岐予測をほぼ完全に失敗させる例」というタイトルからは、「分岐予測ミス率が100%の例」とも捉えられるが、ここでは実質ただのヤマ勘になっている「分岐予測ミス率50%の例」を挙げている
- xorshiftアルゴリズムにより疑似乱数を生成し、その最下位ビットの値によって分岐する

#### 4.6.2 分岐予測をほぼ完全に成功させる例

- xorshift命令を残しつつ、分岐の条件を必ず成立するように変更した結果、分岐予測がほぼ100%成功するようになり、結果として実行サイクル数が約1/3に、すなわち性能が約3倍程度に向上した
  - これは分岐予測と投機実行による効果

#### 4.6.3 分岐予測がときどき失敗する状況

- xorshiftアルゴリズムによる疑似乱数の「下位2ビットが0のとき」「下位3ビットが0のとき」とすることで、偏りを「25%成立」「12.5%成立」のように調整することができる
- 偏りがマスに連れて徐々に分岐予測ミスが減っていく

### 4.7 本章のまとめ

- 分岐命令により、分岐命令の実行と分岐先命令のフェッチ開始が逐次化され、ソフトウェアの実行が遅くなる
- 分岐予測はその影響を緩和するが、あくまでも過去の情報に基づくものであり、予測対象そのものが変化するために予測が外れる可能性もある

## 5. キャッシュメモリ

- キャッシュメモリは、分岐命令と双璧をなす、ソフトウェアの実行を遅くする要因の一つ
  - ちょっと言い方が不適切な気がする。ソフトウェアの実行を早くするための仕組みだが、キャッシュミスがすることもあり、そのときに分岐予測ミス同様パイプラインに大きな影響を与える、ということだと理解した

### 5.1 メモリアクセスに伴うパイプラインの停滞

- CPUからDRAMへのメモリアクセスには、サイクル数にして数10サイクルから100サイクル規模の時間が費やされる
  - DRAMアクセス自体にかかる時間
  - CPUとDRAM間のバス経路の実装にかかる時間
- 命令フェッチ・データのロード・ストアにおいて、メモリアクセスが発生する
  - 命令フェッチに伴う待ちについては、後続の命令の供給が追いつかないため、アウトオブオーダー実行でも埋められない
- RISCではデータメモリへのメモリアクセスが可能な命令が限定される
  - 命令の発行を複数のサイクルに渡って制御する必要をなくし、パイプラインを滞りにくくするため
  - 命令のスケジューリングの自由度を向上するため

### 5.2 キャッシュメモリによる緩和

- キャッシュミスの要因は、「初期参照ミス」「容量性ミス」「競合性ミス」の３種類に整理される

### 初回のアクセスは遅い（初期参照ミス）

#### 5.3.1 キャッシュライン

- 空間局所性：メモリアクセスにおいて、近いアドレスの要素が一緒に使われる可能性が高いという性質
- キャッシュライン：該当アドレスへのアクセス時に近いアドレスの要素もまとめて一緒にキャッシュにコピーする。まとめる単位をキャッシュラインと呼び、64byteが一般的。
- デメリット：実際にアクセスがあれば問題ないが、キャッシュしたにも関わらずアクセスしなければ下記の課題につながる
  - キャッシュ容量を圧迫する
  - 主記憶からキャッシュへのコピーの時間が増加する
  - 主記憶への余分なアクセスが生じる（ライトバックの単位もキャッシュラインになるので、書き込みも増える）

#### 5.3.2 プリフェッチ

- プリフェッチ：特定のアドレスの要素を主記憶からキャッシュへと先行的にコピーする

- 明示的プリフェッチ：専用の命令
- 暗黙的プリフェッチ：例えば、一定間隔のアドレスパターンに対するメモリアクセスを検知して、次のアドレスを予測し投機的にプリフェッチを行うこと

#### 5.3.3 ソフトウェアによる緩和

- 初期参照ミスを避けることは難しいが、キャッシュラインとプリフェッチを意識することで、性能に寄与できる
- キャッシュライン
  - 時間的に近いタイミングで使用されるデータを空間的に近い場所に配置する
  - 配列構造のようなデータに対するアクセスで連続的な添字を利用する。多重配列では、内側からループさせる（Cでは右側の添字）
- プリフェッチ
  - データのアクセスパターンが予測できる場合にプリフェッチ命令を検討する
  - 暗黙的プリフェッチが機能しやすいように、どちらでも良ければ規則的なメモリアクセスを優先する
 
  ### 5.4 容量を超えるアクセスは遅い(容量性ミス)

  - 「リプレースメント」:キャッシュの容量を超えるメモリアクセスが発生した場合に、キャッシュライン単位で古いキャッシュを追い出す。このとき、ダーティだったらライトバックする。
 
  #### 5.4.1 ハードウェアを大容量化する

  - SRAMは1サイクルで大量のデータから任意の一個を選択しなければならず、今の技術では、32kb,64kbを大きく超える大規模化は難しい

  #### 5.4.2 キャッシュの階層化による緩和

  - L1キャッシュだと4-5サイクルに対し、L2キャッシュだと14-15サイクル
 
  #### 5.4.3 明示的なキャッシュ操作による緩和

  - 2回以上アクセスすることがないことがわかっているデータを最初からキャッシュ対象外にする
  - しばらく使用しないアドレスを明示的にキャッシュから追い出す
 
  #### 5.4.4 ソフトウェアによる緩和

  - 巨大な配列をL1キャッシュの容量に合わせて分割する
  - ストリームデータのように一回しか使わないデータでは、キャッシュを使わないようにする
  - キャッシュはプロセス間の共有資源なので、プロセスコンテキストスイッチを減らす
  - SMT(ハイパースレッディング)は2つのスレッドが同時にキャッシュ資源を使うため、容量性ミスの要因になり得る

### 5.5 アドレスの一部が競合するアクセスも遅い（競合性ミス）

- アドレスとキャッシュインデックスとの対応づけには、主に2つの方式がある
  - フルアソシアティブ
  - セットアソシアティブ
  - 高速にキャッシュをみつけるため、基本はセットアソシアティブ
- 同一インデックスを割り当てられるアドレスにアクセスした場合、競合性ミスが生じる
- way数を増やすことで、競合性ミスを低減できる
- 2のべき乗単位のループを避けることで、競合性ミスの可能性を低減することができる
- ｢カラーリング｣:インデックスをずらしながらメモリを割り当てる手法

### 5.6 キャッシュミスの測定

- 異なるキャッシュラインであっても、キャッシュラインの数を上回らないようにアクセスすれば、キャッシュミスはほとんど起こらない
- 但し、2048バイト単位でアクセスするメモリを変えた場合、CPUアーキテクチャによっては同一キャッシュラインに割り当てられることで、連想度が不足し、競合性ミスが起こる場合がある
- `perf`コマンドでキャッシュミスの回数を計測することができる

## 6. 仮想記憶

### 6.1 仮想記憶でできること

- 不連続な物理アドレスを連続な仮想アドレスとして見せる
- ユーザのソフトウェアを起動ごとに異なる物理アドレスに再配置する
- 同じ0番地から始まる複数のソフトウェアを同時に干渉なく並走させる
- 主記憶に配置しきれないデータを、２時期置くに配置する
- ページテーブルは主記憶上に格納される

### 6.2 アドレス変換に伴うメモリアクセス

- 「テーブルウォーク」：ページテーブルからアドレス変換のルールを取得すること。多段になっていて複数回アクセスするため
- 命令フェッチやデータのロードストアには、テーブルウォークと本来のアクセスのために２回のメモリアクセスが必要

### 6.3 TLBによる緩和

- 「TLB (Translation Lookaside Buffer)」：ページテーブルの一部を主記憶からコピーして手元においておくための高速かつ小さなハードウェア

### 6.4 TLBは外れる

- ｢TLBミス｣:メモリアクセス時に対象のエントリがTLBにないこと
- TLBミスの要因にはキャッシュミス同様、初期参照ミス、容量性ミス、競合性ミスがある
- 空間局所性が高いプログラムでは、キャッシュミスよりTLBミスの方が起こりにくい
- L2 TLBでミスした場合、テーブルウォークに数百サイクルかかるため、発生時のダメージはキャッシュミスより大きい
- データアクセス時ならアウトオブオーダー実行で多少緩和できる可能性があるが、命令フェッチ時にはそれすらできない

### 6.5 ソフトウェアによる緩和

- 空間局所性を高める
  - ページサイズを超える単位でのメモリアクセスを減らす
  - L1 TLB / L2 TLBでカバーできるアドレス範囲に処理を分割する
  - 同時間帯に使用される関数やデータを近いセクションに集める
- ページテーブルの切り替えを減らす
  - プロセスの数を減らす
- ペー−じサイズを大きくする
  - 初期参照ミス・容量性ミスを減らすことができる
  - ただし、大きくしすぎると主記憶を効率よく使用できなくなり、スワップを誘発する
- TLBへの直接操作を行う
  - 使用しない仮想アドレスのエントリをTLBから追い出す
  - キャッシュミスの対策として実施するキャッシュの直接操作と比較すると、有効性は低い

### 6.6 仮想記憶についての補足

- 「ページフォールト」：メモリアクセス時にアクセス対象が主記憶上に存在しておらず、２次記憶上に存在する状況。２次記憶へのアクセスは主記憶と比較しても更に遥かに遅いので、影響が非常に大きい
- 「メモリ属性」：ページテーブルの各エントリに対して、キャッシュの使用可否やメモリ順序入れ替えの可否などを設定する手段。これによりシステムの総合性能を向上できる可能性がある。

### 6.7 TLBミスの計測実験

- 近年のx86-64 CPUでは、数千エントリ規模のL2 TLBが搭載されている
- ページサイズは一般的には4KB
- 4KB間隔で256回アクセスするをループしたら、ほとんどL2 TLBにヒットするはず
- 4KB間隔で8192回アクセスするをループしたら、容量性ミスが多発してほとんどミスするはず
  - 古いエントリが順次追い出されるので、ずっとTLBミスし続ける

## 7. I/O

- さらっと出てくるキーボードの絵が分割キーボードで、ディスプレイの絵がモニタアーム付きであるところに、著者の並々ならないこだわりを感じる

### 7.1 I/Oアクセスの方法

- 「メモリマップドI/O」：I/Oデバイスをメモリのように見せ、メモリの物理アドレス空間経由で通常のメモリアクセス命令によりアクセスする方式。ArmやRISC-Vはこちらのみサポート。
- 「I/Oアドレス空間」：I/Oデバイス専用のアドレス空間。専用のI/O命令でアクセスする。x86はこちらもサポート

### 7.2 I/Oアクセスで実現できること

- I/Oライトアクセスにより、I/Oデバイスに指示をだす
- I/Oリードアクセスにより、I/Oデバイスの状態を確認する
- I/OデバイスからCPUレジスタを介して主記憶へデータを転送することができるが、その場合I/Oリードアクセスとストアの２ステップが必要であり、かつ、それらは真の依存関係を持つので、多くの後続命令の実行機会が失われる

### 7.3 I/Oアクセスは遅い

- I/Oデバイスはコストと消費電力を削減するために、意図的にCPUと比較して低い動作周波数で動く
- I/Oバスもコストと消費電力を削減するために、意図的にCPUと比較して低い動作周波数で動かす場合がある
- 多数のI/Oデバイスを接続するために、識別して選択する仕組みが必要となるため、バスの回路規模が大きくなり、アクセスにかかるサイクルが増加する
- 新規デバイスへの対応や動的な着脱を可能にするため、データ送受信に複数の手順を要するバス規格もあり、その場合さらにアクセスに必要なサイクルすが増加する
- I/Oデバイスにアクセスするために、プロトコル仕様や動作周波数が異なる複数のバスを乗り替える必要がある場合、変換のために更にサイクル数が増加する
- I/Oデバイス本体へのアクセスが必要となるため、キャッシュは使えない
- I/Oデバイスへの「１回のアクセス」が意味を持つ場合があるため、投機的プリフェッチが使えない
- I/Oデバイスへのアクセスの順序が意味を持つ場合があるため、アウトオブオーダー実行が使えない

### 7.4 ハードウェアによる支援

- 割込によりポーリングを回避し、無駄な空きサイクルの発生を抑制する。割込は設定や処理が必要な上、難易度も高いので利用箇所は見極める必要がある。
- DMAによりCPUを介さずにメモリ間でデータを転送することで、CPUの負荷を避ける。DMAコントローラは共有資源なので調停が必要であり、完了待ちも必要。
- CPUによっては、I/Oアクセス間の順序を制御する手段を提供しており、これを活用することで改善が可能。また、CPUによっては、I/Oデバイスから主記憶に直接アクセス可能な場合もある。さらにキャッシュを共有している場合もある。

### 7.5 ソフトウェアによる緩和

- 必ずしも毎回デバイス本体へアクセスしなくても成立するI/Oデバイスの場合、主記憶でバッファリングする
  - 例：ハードディスクやSSDに対する「ページキャッシュ」や「バッファキャッシュ」
- I/Oアクセスの頻度を減らしたり、まとめることで、CPUパイプラインにおける無駄な空きサイクルを減らす
  - 例：I/Oデバイスとの一回あたりのデータ転送量を減らす。ただし、この方法だと応答性は劣化する

### 7.6 I/Oの挙動を確認するアセンブリプログラム例

- RTCは１秒以下の時刻精度は無いが、PCの電源が停止している間もバッテリ駆動によって現在の日時情報を計数し続ける
- Linuxでは、`/proc/ioports`により、I/Oアドレス空間に割り当てられているデバイスの一覧とアドレスを知ることができる
- PCI Expressでは、「何番目のバスの何番目のデバイスの何番目のファンクションについてのどの情報を知りたいか」を特定のI/Oアドレス空間に書き込んでから別のI/Oアドレス空間を読み出すことで、コンフィグレーション情報を読み出せる
- I/O命令のレイテンシを計測する場合、x86におけるI/O命令は先行または後続の命令との間で逐次化を行うので、単純に繰り返し実行するだけで個々の命令のレイテンシを計測できる

## 8. システムコール、例外、割り込み

### 8.1 用語の定義

- システムコール：特権レベルの変更命令によって明示的に発生させる命令流の切り替え
- 例外：命令実行時に発生する稀なケースをハードウェアで検出した際、暗黙的に発生する命令流の切り替え
- 割り込み：外部からの要求による命令流の切り替え

### 8.4 割り込みとその利用シーン

- CPUからみれば、割り込みコントローラもI/Oデバイスの一つであり、割り込みコントローラの設定（優先度など）もCPUからのI/Oライトアクセスで行う
- CPU側にも、割り込みの設定（割り込み発生時にどのアドレスにジャンプするかなど）を行う
- 割り込みによるイベント駆動によって、ソフトウェアによるポーリングを抑制し、デバイスにおける素早い応答を可能にする

### 8.5 例外・割り込み系のふるまい

- システムコール、例外、割り込みは、用途は異なるが、いずれも命令流の特別な切り替えを行う事象であり、CPUパイプラインにおける挙動は似ている
- いずれも切り替え先の命令（ハンドラ）のアドレスをRAM上に格納した「ベクタテーブル」を参照し、PCレジスタを変更する
- 事象発生による命令流の切り替え時点で、戻り先のアドレス及びコンテキスト（特権レベルやレジスタの値）を特別なレジスタなどに保存しておく
- 戻り先のアドレスは、
  - システムコール命令の場合は、システムコール完了後に次の命令から継続できるよう、次の命令アドレス
  - 例外の場合は、適切な処理ができた場合に再実行できるよう、例外発生した命令アドレス
  - 割り込みの場合は、割り込まれた処理を再開できるよう、割り込まれた命令のアドレス
- 特権レベルでI/Oを保護するOSでは、I/Oアクセスのたびにシステムコールが必要となり、システムコールとI/Oの２つのオーバーヘッドが都度必要となるため、ライブラリ層でバッファなどを活用しシステムコールの頻度を減らす工夫が、OS層でI/Oの頻度を減らす工夫がなされる
- 割り込み
  - マスクされることで受け付けられないことがある
  - 割り込みレベルによって、優先度がつけられることがある
  - 多重に発生する可能性がある
  - 非同期でいつ発生するかわからないため、アトミックな操作が中断されないよう割り込み禁止区間を設定する必要がある
  - 割り込み禁止区間が長いと割り込み応答性能が悪化するため、必要最低限にする必要がある
  - 時分割でスケジューリングする場合、割り込み処理時間分、割り込まれたプロセスのタイムスロットが消費されるので、割り込まれたプロセスの動作が遅くなったように見える

### 8.6 例外・割り込み系がCPUの動作を遅くする背景

- 分岐予測が効かない
  - システムコールは原理的には予測対象にできるが、バグやセキュリティ上の課題を誘発するので一般的に慎重
- 特権レベルの変更前後は逐次的な実行が必要
  - 特権の切り替えに先行する命令に特権レベルの変更は影響してはならない
  - 特権の切り替え以降の命令に確実に特権レベルの変更が反映されなければならない
  - 以上のことから、特権の切替時には、一旦パイプラインを空にするため、パイプラインフラッシュが行われる
  - これらのような完全な逐次化を行わないという選択も原理的には可能だが、バグやセキュリティ上の課題を誘発する
- ベクタテーブルのアクセスにおけるキャッシュミス
  - システムコール・例外・割り込みが稀なので、RAM上のベクタテーブルを参照する際のメモリアクセスでキャッシュミスが起こりやすい
- ハンドラ内での分岐予測ミス、キャッシュミス、TLBミス
  - システムコール・例外・割り込みが稀なので、ハンドラ内で分岐予測ミス、キャッシュミス、TLBはミスが発生しやすい
- ハンドラから戻るときもパイプラインフラッシュによる逐次化が必要

### 8.7 ソフトウェアによる対策

- 命令流の特別な切り替えは、頻度が低い事象であるため、対策の優先度は低い
- 一方で、もし課題になったときはシステムレベルでの検討が必要であり、かつCPUごとの差異も大きいため、難しい

- 対策
  - システムコールの頻度を低減する
    - バッファリング
    - OSレベルの処理の一部をユーザレベルで実行する
  - 割り込みの頻度を減らす。ただし、応答性とのトレードオフ
  - 割り込み処理によってタイムスロットが奪われる可能性があること、アトミックな操作を割り込みによって中断されないようにまもることを考慮する
